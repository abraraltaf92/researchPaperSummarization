Recent work has motivated the need for systemsthat support �Information Synthesis� tasks, in whicha user seeks a global understanding of a topic orstory (Amigo et al., 2004).
Currently, we address the question-focused sentence retrieval task.
(Robertson et al.,1992; Salton et al., 1993)), it remains important andyet often overlooked.
(7:6) Figure 1: Question tracking interface to a summarization system.
There areedges between nodes for which the cosine similarity between the respective pair of sentences exceedsa given threshold.
Therefore, sentences that contain the most salient information in the document set should be very centralwithin the graph.Figure 2 shows an example of a similarity graph for a set of five input sentences, using a cosine similarity threshold of 0.15.
Below,we describe a topic-sensitive version of LexRank,which is more appropriate for the question-focusedsentence retrieval problem.
In the new approach, the 916 score of a sentence is determined by a mixture modelof the relevance of the sentence to the query and thesimilarity of the sentence to other high-scoring sentences.
Then the relevance of a sentence s tothe question q is computed by: rel(s|q) =Xw?q log(tfw,s + 1)� log(tfw,q + 1) � idfw (2) where tfw,s and tfw,q are the number of times wappears in s and q, respectively.
This model hasproven to be successful in query-based sentence retrieval (Allan et al., 2003), and is used as our competitive baseline in this study (e.g. Tables 4, 5 and7).
1 0.03614457831325301 At least two people are dead, inclu...
Such a matrix is called stochasticand defines a Markov chain.
With probability (1-d), a transitionis made to the nodes that are lexically similar to thecurrent node.
It was also the model used torank sentences in (Erkan and Radev, 2004).
A non-ergodic Markov chain can bemade ergodic by reserving a small probability for jumping toany other state from the current state (Page et al., 1998).
�Newstracker� clusters were collected automatically by our Web-based news summarization system.
For each sentence and question pair in a givencluster, the judges were asked to indicate whetheror not the sentence contained a complete answerto the question.
We appliedall four of these configurations to our unseen development/test data, in order to see if we could furtherdifferentiate their performances.
While LexRank outperforms the baseline system on the first two clusters both in termsof MRR and TRDR, their performances are not substantially different on the third cluster.
The idea behind using LexRank for sentence retrieval is that a system that considers only the similarity between candidate sentences and the inputquery, and not the similarity between the candidatesentences themselves, is likely to miss some important sentences.
Table 9: Top ranked sentences using theLR[0.20,0.95] system on the question �What causedthe Kursk to sink?� answers from the retrieved sentences.
In this case,the sentences selected by our system would be sentto an answer identification component for furtherprocessing.
As discussed in Section 2, our goal wasto develop a topic-sensitive version of LexRank andto use it to improve a baseline system, which hadpreviously been used successfully for query-basedsentence retrieval (Allan et al., 2003).Recent work has motivated the need for systemsthat support �Information Synthesis� tasks, in whicha user seeks a global understanding of a topic orstory (Amigo et al., 2004).
Currently, we address the question-focused sentence retrieval task.
(Robertson et al.,1992; Salton et al., 1993)), it remains important andyet often overlooked.
(7:6) Figure 1: Question tracking interface to a summarization system.
There areedges between nodes for which the cosine similarity between the respective pair of sentences exceedsa given threshold.
Therefore, sentences that contain the most salient information in the document set should be very centralwithin the graph.Figure 2 shows an example of a similarity graph for a set of five input sentences, using a cosine similarity threshold of 0.15.
Below,we describe a topic-sensitive version of LexRank,which is more appropriate for the question-focusedsentence retrieval problem.
In the new approach, the 916 score of a sentence is determined by a mixture modelof the relevance of the sentence to the query and thesimilarity of the sentence to other high-scoring sentences.
Then the relevance of a sentence s tothe question q is computed by: rel(s|q) =Xw?q log(tfw,s + 1)� log(tfw,q + 1) � idfw (2) where tfw,s and tfw,q are the number of times wappears in s and q, respectively.
This model hasproven to be successful in query-based sentence retrieval (Allan et al., 2003), and is used as our competitive baseline in this study (e.g. Tables 4, 5 and7).
1 0.03614457831325301 At least two people are dead, inclu...
Such a matrix is called stochasticand defines a Markov chain.
With probability (1-d), a transitionis made to the nodes that are lexically similar to thecurrent node.
It was also the model used torank sentences in (Erkan and Radev, 2004).
A non-ergodic Markov chain can bemade ergodic by reserving a small probability for jumping toany other state from the current state (Page et al., 1998).
�Newstracker� clusters were collected automatically by our Web-based news summarization system.
For each sentence and question pair in a givencluster, the judges were asked to indicate whetheror not the sentence contained a complete answerto the question.
We appliedall four of these configurations to our unseen development/test data, in order to see if we could furtherdifferentiate their performances.
While LexRank outperforms the baseline system on the first two clusters both in termsof MRR and TRDR, their performances are not substantially different on the third cluster.
The idea behind using LexRank for sentence retrieval is that a system that considers only the similarity between candidate sentences and the inputquery, and not the similarity between the candidatesentences themselves, is likely to miss some important sentences.
Table 9: Top ranked sentences using theLR[0.20,0.95] system on the question �What causedthe Kursk to sink?� answers from the retrieved sentences.
In this case,the sentences selected by our system would be sentto an answer identification component for furtherprocessing.
As discussed in Section 2, our goal wasto develop a topic-sensitive version of LexRank andto use it to improve a baseline system, which hadpreviously been used successfully for query-basedsentence retrieval (Allan et al., 2003).Recent work has motivated the need for systemsthat support �Information Synthesis� tasks, in whicha user seeks a global understanding of a topic orstory (Amigo et al., 2004).
Currently, we address the question-focused sentence retrieval task.
(Robertson et al.,1992; Salton et al., 1993)), it remains important andyet often overlooked.
(7:6) Figure 1: Question tracking interface to a summarization system.
There areedges between nodes for which the cosine similarity between the respective pair of sentences exceedsa given threshold.
Therefore, sentences that contain the most salient information in the document set should be very centralwithin the graph.Figure 2 shows an example of a similarity graph for a set of five input sentences, using a cosine similarity threshold of 0.15.
Below,we describe a topic-sensitive version of LexRank,which is more appropriate for the question-focusedsentence retrieval problem.
In the new approach, the 916 score of a sentence is determined by a mixture modelof the relevance of the sentence to the query and thesimilarity of the sentence to other high-scoring sentences.
Then the relevance of a sentence s tothe question q is computed by: rel(s|q) =Xw?q log(tfw,s + 1)� log(tfw,q + 1) � idfw (2) where tfw,s and tfw,q are the number of times wappears in s and q, respectively.
This model hasproven to be successful in query-based sentence retrieval (Allan et al., 2003), and is used as our competitive baseline in this study (e.g. Tables 4, 5 and7).
1 0.03614457831325301 At least two people are dead, inclu...
Such a matrix is called stochasticand defines a Markov chain.
With probability (1-d), a transitionis made to the nodes that are lexically similar to thecurrent node.
It was also the model used torank sentences in (Erkan and Radev, 2004).
A non-ergodic Markov chain can bemade ergodic by reserving a small probability for jumping toany other state from the current state (Page et al., 1998).
�Newstracker� clusters were collected automatically by our Web-based news summarization system.
For each sentence and question pair in a givencluster, the judges were asked to indicate whetheror not the sentence contained a complete answerto the question.
We appliedall four of these configurations to our unseen development/test data, in order to see if we could furtherdifferentiate their performances.
While LexRank outperforms the baseline system on the first two clusters both in termsof MRR and TRDR, their performances are not substantially different on the third cluster.
The idea behind using LexRank for sentence retrieval is that a system that considers only the similarity between candidate sentences and the inputquery, and not the similarity between the candidatesentences themselves, is likely to miss some important sentences.
Table 9: Top ranked sentences using theLR[0.20,0.95] system on the question �What causedthe Kursk to sink?� answers from the retrieved sentences.
In this case,the sentences selected by our system would be sentto an answer identification component for furtherprocessing.
As discussed in Section 2, our goal wasto develop a topic-sensitive version of LexRank andto use it to improve a baseline system, which hadpreviously been used successfully for query-basedsentence retrieval (Allan et al., 2003).Recent work has motivated the need for systemsthat support �Information Synthesis� tasks, in whicha user seeks a global understanding of a topic orstory (Amigo et al., 2004).
Currently, we address the question-focused sentence retrieval task.
(Robertson et al.,1992; Salton et al., 1993)), it remains important andyet often overlooked.
(7:6) Figure 1: Question tracking interface to a summarization system.
There areedges between nodes for which the cosine similarity between the respective pair of sentences exceedsa given threshold.
Therefore, sentences that contain the most salient information in the document set should be very centralwithin the graph.Figure 2 shows an example of a similarity graph for a set of five input sentences, using a cosine similarity threshold of 0.15.
Below,we describe a topic-sensitive version of LexRank,which is more appropriate for the question-focusedsentence retrieval problem.
In the new approach, the 916 score of a sentence is determined by a mixture modelof the relevance of the sentence to the query and thesimilarity of the sentence to other high-scoring sentences.
Then the relevance of a sentence s tothe question q is computed by: rel(s|q) =Xw?q log(tfw,s + 1)� log(tfw,q + 1) � idfw (2) where tfw,s and tfw,q are the number of times wappears in s and q, respectively.
This model hasproven to be successful in query-based sentence retrieval (Allan et al., 2003), and is used as our competitive baseline in this study (e.g. Tables 4, 5 and7).
1 0.03614457831325301 At least two people are dead, inclu...
Such a matrix is called stochasticand defines a Markov chain.
With probability (1-d), a transitionis made to the nodes that are lexically similar to thecurrent node.
It was also the model used torank sentences in (Erkan and Radev, 2004).
A non-ergodic Markov chain can bemade ergodic by reserving a small probability for jumping toany other state from the current state (Page et al., 1998).
�Newstracker� clusters were collected automatically by our Web-based news summarization system.
For each sentence and question pair in a givencluster, the judges were asked to indicate whetheror not the sentence contained a complete answerto the question.
We appliedall four of these configurations to our unseen development/test data, in order to see if we could furtherdifferentiate their performances.
While LexRank outperforms the baseline system on the first two clusters both in termsof MRR and TRDR, their performances are not substantially different on the third cluster.
The idea behind using LexRank for sentence retrieval is that a system that considers only the similarity between candidate sentences and the inputquery, and not the similarity between the candidatesentences themselves, is likely to miss some important sentences.
Table 9: Top ranked sentences using theLR[0.20,0.95] system on the question �What causedthe Kursk to sink?� answers from the retrieved sentences.
In this case,the sentences selected by our system would be sentto an answer identification component for furtherprocessing.
As discussed in Section 2, our goal wasto develop a topic-sensitive version of LexRank andto use it to improve a baseline system, which hadpreviously been used successfully for query-basedsentence retrieval (Allan et al., 2003).