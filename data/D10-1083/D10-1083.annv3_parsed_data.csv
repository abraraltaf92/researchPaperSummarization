D11-1056.txt,Following Lee et al.
D11-1056.txt,"(2010), we report the best and median settings of hyperparameters based on the F- score, in addition to inferred values."
D11-1059.txt,"However, despite a recent proliferation of syntactic class induction systems (Biemann, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Berg-Kirkpatrick et al., 2010; Lee et al., 2010)"
D11-1059.txt,"This property is not strictly true of linguistic data, but is a good approximation"
D11-1059.txt,"More recently, Lee et al."
D11-1059.txt,"(2010) presented a new type-based model, and also reported very good results."
D11-1059.txt,"Sequence models are by far the most common method of supervised part- of-speech tagging, and have also been widely used for unsupervised part-of-speech tagging both with and without a dictionary (Smith and Eisner, 2005; Haghighi and Klein, 2006; Goldwater and Griffiths, 2007; Johnson, 2007; Ravi and Knight, 2009; Lee et al., 2010)."
D11-1059.txt,"As in previous work (Lee et al., 2010), we find that the one-class-per-type restriction boosts performance considerably over a comparable token- based model and yields results that are comparable to state-of-the-art even without the use of morphology or alignment features."
D11-1059.txt,2 One could approximate this likelihood term by assuming independence between all nj feature tokens of word type j. This is the approach taken by Lee et al.
D11-1059.txt,(2010).
D11-1059.txt,Following Lee et al.
D11-1059.txt,(2010) we used only the training sections for each language.
D12-1086.txt,"Given that close to 95% of the word occurrences in human labeled data are tagged with their most frequent part of speech (Lee et al., 2010)"
D12-1125.txt,"vised POS induction algorithm (Lee et al., 2010)"
D12-1127.txt,"Unsupervised induction of POS taggers offers the possibility of avoiding costly annotation, but despite recent progress, the accuracy of unsupervised POS taggers still falls far behind supervised systems, and is not suitable for most applications (Berg- Kirkpatrick et al., 2010; GracÂ¸a et al., 2011; Lee et al., 2010)."
D13-1004.txt,"Systems for inducing syntactic categories often make use of morpheme-like features, such as word-final characters (Smith and Eisner, 2005; Haghighi and Klein, 2006; Berg-Kirkpatrick et al., 2010; Lee et al., 2010)"
N12-1045.txt,"Several unsupervised POS induction systems make use of morphological features (Blunsom and Cohn, 2011; Lee et al., 2010; Berg-Kirkpatrick et al., 2010; Clark, 2003; Christodoulopoulos et al., 2011)"
P11-1087.txt,Recently Lee et al.
P11-1087.txt,"(2010) combined the one class per word type constraint (Brown et al., 1992) in a HMM with a Dirichlet prior to achieve both forms of sparsity."
P11-1087.txt,"However this work approximated the derivation of the Gibbs sampler (omitting the interdependence between events when sampling from a collapsed model), resulting in a model which underperformed Brown et al."
P11-1087.txt,(1992)â€™s one-class HMM.
P11-1087.txt,It is also interesting to compare the bigram PYP1HMM to the closely related model of Lee et al.
P11-1087.txt,(2010).
P11-1087.txt,"That model incorrectly assumed independence of the conditional sampling distributions, resulting in a accuracy of 66.4%"
P13-1150.txt,"Similar constraints have been developed for part-of-speech tagging (Lee et al., 2010; Christodoulopoulos et al., 2011)"
W11-0301.txt,"Here, W t refers to the set of word types that are generated by tag t. In other words, conditioned on tag t, we can only generate word w from the set of word types in W t which is generated earlier (Lee et al., 2010)."
W12-1914.txt,"Second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes Ravi and Knight (2009), Lee et al."
W12-1914.txt,"(2010), Lamar et al."
